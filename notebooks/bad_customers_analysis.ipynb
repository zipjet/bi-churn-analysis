{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "pd.options.mode.chained_assignment = None\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/churn_dataset.csv\")\n",
    "df_cluster = pd.read_csv('data/clustered_customers.csv')[['customer_db_id', 'cluster', 'cluster_name', 'freq_mean', 'freq_median']]\n",
    "df = df.merge(df_cluster, on='customer_db_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zips = pd.read_csv(\"data/zips_berlin.csv\", header=None)\n",
    "df_zips.columns = ['city_part', 'zips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zips['zips'] = df_zips['zips'].apply(lambda x: x.split(';'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_part</th>\n",
       "      <th>zips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mitte</td>\n",
       "      <td>[10115, 10117, 10119, 10178, 10179, 10435, 105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Friedrichshain-Kreuzberg</td>\n",
       "      <td>[10179, 10243, 10245, 10247, 10249, 10367, 107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pankow</td>\n",
       "      <td>[10119, 10247, 10249, 10405, 10407, 10409, 104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charlottenburg-Wilmersdorf</td>\n",
       "      <td>[10553, 10585, 10587, 10589, 10623, 10625, 106...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spandau</td>\n",
       "      <td>[13581, 13583, 13585, 13587, 13589, 13591, 135...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    city_part  \\\n",
       "0                       Mitte   \n",
       "1    Friedrichshain-Kreuzberg   \n",
       "2                      Pankow   \n",
       "3  Charlottenburg-Wilmersdorf   \n",
       "4                     Spandau   \n",
       "\n",
       "                                                zips  \n",
       "0  [10115, 10117, 10119, 10178, 10179, 10435, 105...  \n",
       "1  [10179, 10243, 10245, 10247, 10249, 10367, 107...  \n",
       "2  [10119, 10247, 10249, 10405, 10407, 10409, 104...  \n",
       "3  [10553, 10585, 10587, 10589, 10623, 10625, 106...  \n",
       "4  [13581, 13583, 13585, 13587, 13589, 13591, 135...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     zips\n",
       "0   10115\n",
       "0   10117\n",
       "0   10119\n",
       "0   10178\n",
       "0   10179\n",
       "0   10435\n",
       "0   10551\n",
       "0   10553\n",
       "0   10555\n",
       "0   10557\n",
       "0   10559\n",
       "0   10623\n",
       "0   10785\n",
       "0   10787\n",
       "0   10963\n",
       "0   10969\n",
       "0   13347\n",
       "0   13349\n",
       "0   13351\n",
       "0   13353\n",
       "0   13355\n",
       "0   13357\n",
       "0   13359\n",
       "0   13405\n",
       "0   13407\n",
       "0   13409\n",
       "0        \n",
       "0        \n",
       "0        \n",
       "0        \n",
       "..    ...\n",
       "11  13409\n",
       "11  13435\n",
       "11  13437\n",
       "11  13439\n",
       "11  13465\n",
       "11  13467\n",
       "11  13469\n",
       "11  13503\n",
       "11  13505\n",
       "11  13507\n",
       "11  13509\n",
       "11  13599\n",
       "11  13629\n",
       "11       \n",
       "11       \n",
       "11       \n",
       "11       \n",
       "11       \n",
       "11       \n",
       "11       \n",
       "11       \n",
       "11       \n",
       "11       \n",
       "11       \n",
       "11       \n",
       "11       \n",
       "11       \n",
       "11       \n",
       "11       \n",
       "11       \n",
       "\n",
       "[396 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_zips.zips.apply(pd.Series)\n",
    "              .stack()\n",
    "              .reset_index(level=1, drop=True)\n",
    "              .to_frame('zips'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['churned'] = [True if x > 2 else False for x in df.churn_factor]\n",
    "df['first_order_voucher_revenue_ratio'] = df.first_order_voucher_value / (df.first_order_voucher_value + df.first_order_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = df.isnull().sum()\n",
    "nans[nans > 0].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_order_products'] = df['first_order_products'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['refunds_unsuccess', 'refunds_success']] = df[['refunds_unsuccess', 'refunds_success']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_cols = ['avg_rating', 'rating_diff', 'last_order_rating', 'rated_orders', 'first_order_rating']\n",
    "df[rating_cols] = df[rating_cols].fillna(-999)\n",
    "df.loc[df.rated_orders > 0, rating_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.aov = df.aov.fillna(0)\n",
    "df.segment = df.segment.fillna('None')\n",
    "df.gender = df.gender.fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.zip = df.zip.fillna('Unknown')\n",
    "df.zip_area = df.zip_area.fillna('Unknown')\n",
    "\n",
    "# df.avg_hub_distance = df.avg_hub_distance.fillna(-999)\n",
    "# df.last_order_hub_distance = df.last_order_hub_distance.fillna(-999)\n",
    "# df.first_order_hub_distance = df.first_order_hub_distance.fillna(-999)\n",
    "# df.laundry_distance = df.laundry_distance.fillna(-999)\n",
    "# df.laundry_rating = df.laundry_rating.fillna(-999)\n",
    "# df.laundry_within_1km = df.laundry_within_1km.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.first_order_date = pd.to_datetime(df.first_order_date)\n",
    "df['first_order_week'] = df['first_order_date'].dt.week\n",
    "df['first_order_year'] = df['first_order_date'].dt.year\n",
    "df['first_order_day'] = df['first_order_date'].dt.day\n",
    "df['first_order_month'] = df['first_order_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.first_order_fac_name = df.first_order_fac_name.fillna('unknown')\n",
    "df.first_order_voucher_channel = df.first_order_voucher_channel.fillna('unknown')\n",
    "df.first_order_voucher_value = df.first_order_voucher_value.fillna(-999)\n",
    "df.first_order_voucher_revenue_ratio = df.first_order_voucher_revenue_ratio.fillna(0)\n",
    "df.last_order_fac_name = df.last_order_fac_name.fillna('unknown')\n",
    "df.last_order_voucher_channel = df.last_order_voucher_channel.fillna('unknown')\n",
    "df.last_order_voucher_value = df.last_order_voucher_value.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if customer cannot be clustered because no information about itemization -> freq_median and freq_mean will be 365\n",
    "df.freq_mean = df.freq_mean.fillna(365)\n",
    "df.freq_median = df.freq_median.fillna(365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(-999)\n",
    "nans = df.isnull().sum()\n",
    "nans[nans > 0].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voucher_channel_le = LabelEncoder()\n",
    "voucher_channel_le.fit(df.first_order_voucher_channel)\n",
    "df['first_order_voucher_channel_enc'] = voucher_channel_le.transform(df.first_order_voucher_channel.tolist())\n",
    "\n",
    "products_le = LabelEncoder()\n",
    "products_le.fit(df.first_order_products)\n",
    "df['first_order_products_enc'] = products_le.transform(df.first_order_products.tolist())\n",
    "\n",
    "facility_le = LabelEncoder()\n",
    "facility_le.fit(df.first_order_fac_name)\n",
    "df['first_order_fac_name_enc'] = facility_le.transform(df.first_order_fac_name.tolist())\n",
    "\n",
    "order_date_le = LabelEncoder()\n",
    "order_date_le.fit(df.first_order_date.sort_values().dt.strftime('%Y-%m-%d'))\n",
    "df['first_order_date_enc'] = order_date_le.transform(df.first_order_date.dt.strftime('%Y-%m-%d').tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad vs Good Voucher Customers\n",
    "*Assumption: Bad customers are customers who had one completed order using a voucher, had a good customer experience and didn't place another order for more than a year. These customers should be excluded from churn analysis.*\n",
    "\n",
    "We want to analyse, if there are any specific features, such as area, channels, products that identify bad customers. In order to analyse, we create a comparison 'Good Customers' group, which are customers, who have returned after their first order with vouchers within a year.\n",
    "\n",
    "Bad Voucher customers: \n",
    "- First_Order_Voucher == TRUE\n",
    "- Completed_Orders == 1\n",
    "- Total_Orders == 1\n",
    "- Last_Order > 365 days ago\n",
    "\n",
    "Good Voucher customers:\n",
    "- First_Order_Voucher == TRUE\n",
    "- Completed_Orders > 1\n",
    "- Second completed order within a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vou = df.loc[df.first_order_voucher & df.completed_orders > 0]\n",
    "df_vou_good = df_vou.loc[(df_vou.completed_orders > 1) & (df_vou.first_order_recency < 365)]\n",
    "df_vou_bad = df_vou.loc[(df_vou.completed_orders == 1) & (df_vou.total_orders == 1) & (df_vou.recency > 365)]\n",
    "\n",
    "df_vou_bad = df_vou_bad.loc[df_vou_bad.first_order_date < \"2017-08-29\"]\n",
    "df_vou_good = df_vou_good.loc[df_vou_good.first_order_date < \"2017-08-29\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Bad customers: ', df_vou_bad.shape[0])\n",
    "print('Number of Good customers: ', df_vou_good.shape[0])\n",
    "\n",
    "df_vou_bad['customer_type'] = 'bad'\n",
    "df_vou_good['customer_type'] = 'good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vou.refunds_success.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad customers with Bad experience\n",
    "*Assumption: If a BAD customer churned because of bad experience, he should be included in the churn analysis*\n",
    "\n",
    "Customers falling into the following groups should not be excluded from analysis:\n",
    "* reclean_order\n",
    "* order_rating < 4\n",
    "* internal_reschedules > 1\n",
    "* refund\n",
    "* order was unpunctual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_vou_bad.groupby(['reclean_orders'])['customer_db_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_vou_bad.groupby(['last_order_rating'])['customer_db_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_vou_bad.groupby(['internal_reschedules'])['customer_db_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_vou_bad.groupby(['refunds_success'])['customer_db_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vou_bad.groupby(['unpunctual_orders'])['customer_db_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both = pd.concat([df_vou_bad, df_vou_good])\n",
    "df_both['customer_type_enc'] = df_both['customer_type'].map({'bad': -1, 'good': 1})\n",
    "\n",
    "df_both['experience'] = 'good'\n",
    "df_both.loc[\n",
    "    (df_both.reclean_orders == 1) |\n",
    "    ((df_both.last_order_rating < 4) & (df_both.last_order_rating > 0)) |\n",
    "    (df_both.refunds_success == 1) |\n",
    "    (df_both.internal_reschedules > 1) |\n",
    "    (df_both.unpunctual_orders == 1), 'experience'] = 'bad'\n",
    "\n",
    "print('Bad with bad experience: ', df_both.loc[(df_both.customer_type == 'bad') & (df_both.experience == 'bad')].shape[0])\n",
    "print('Bad with good experience: ',df_both.loc[(df_both.customer_type == 'bad') & (df_both.experience == 'good')].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad experience Facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_both.loc[df_both.experience == 'bad', 'last_order_fac_name'].value_counts() \n",
    " / df_both.last_order_fac_name.value_counts()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both.to_csv('./data/pbi/bad_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad Customers with Good Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bad_vs_good_by_column(df_both, column_name, print_df=False):\n",
    "    df_bad = df_both.loc[df_both.customer_type == 'bad']\\\n",
    "                .groupby(column_name)['customer_db_id']\\\n",
    "                .nunique() / df_vou_bad.shape[0]\n",
    "    df_good = df_both.loc[df_both.customer_type == 'good']\\\n",
    "                .groupby(column_name)['customer_db_id']\\\n",
    "                .nunique() / df_vou_good.shape[0]\n",
    "    \n",
    "    df_diff = df_good - df_bad\n",
    "    df_diff_relative = df_diff / (df_bad + df_good)\n",
    "    df = pd.concat([df_bad, df_good, df_diff, df_diff_relative], \n",
    "                  axis=1, keys=['bad', 'good', 'diff', 'diff_relative'], sort=True)\n",
    "    \n",
    "    if print_df:\n",
    "        print(df)\n",
    "    \n",
    "    df = df.sort_values('diff', ascending=False)\n",
    "    df[['bad', 'good']].plot(kind='bar', title=column_name)\n",
    "    df[['diff']].plot(kind='bar', title='diff (+ more good / - more bad)', color='orange')\n",
    "#     df[['diff_relative']].sort_values('diff_relative', ascending=False).plot(kind='bar', title='diff relative (diff / all customers)', color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bad_vs_good_dist(df_both, column_name):\n",
    "    sns.categorical.violinplot(data=df_both, x='customer_type', y=column_name)\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(2, sharex=True, sharey=True,figsize=(6,6))\n",
    "    sns.distplot(df_both.loc[df_both.customer_type == 'bad', column_name], ax=ax1, color='red', kde=False, bins=10)\n",
    "    ax1.set_title('Bad Customers')\n",
    "    sns.distplot(df_both.loc[df_both.customer_type == 'good', column_name], ax=ax2, color='blue', kde=False, bins=10)\n",
    "    ax2.set_title('Good Customers')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bad_vs_good_dist(df_both.loc[(df_both.cluster != -999)], 'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bad_vs_good_by_column(df_both.loc[(df_both.cluster != -999)], 'cluster_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voucher Channel\n",
    "*Assumption: The channel through which the customer has received the voucher influences if the acquired customer is going to come back after the first order.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bad_vs_good_by_column(df_both.loc[df_both.experience == 'good'], 'first_order_voucher_channel', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both.groupby(['customer_type', 'experience', 'first_order_voucher_channel'])\\\n",
    "        ['customer_db_id'].nunique().reset_index()\\\n",
    "        .to_csv('./data/pbi/bad_cust.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both.loc[(df_both.customer_type == 'bad') & (df_both.experience == 'good')].first_order_voucher_channel.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Customers that have acquired their vouchers from the following channels are **likely to churn after first order, even if they had a good customer experience**, and should be excluded from the analysis.\n",
    "* SEO\n",
    "* SEM\n",
    "* Appco/Direct Sales\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_voucher_channels = ['SEO', 'SEM', 'Appco/Direct Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voucher Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bad_vs_good_dist(df_both, 'first_order_voucher_revenue_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both.loc[df_both.first_order_voucher_revenue_ratio > 0.9, 'customer_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both.loc[(df_both.first_order_voucher_channel == 'Appco/Direct Sales') & \n",
    "            (df_both.first_order_voucher_revenue_ratio > 0.9), \n",
    "            'customer_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bad_vs_good_by_column(df_both.loc[df_both.first_order_voucher_revenue_ratio > 0.9], 'first_order_voucher_channel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Order Revenue\n",
    "*Assumption: Depending on how much the customer actually spent on their first voucher order, determines if they are going to order again or not. Customer who spend more, tend to be good customers, because they can afford our service regularly*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = df_both[['customer_type', 'first_order_revenue']]\n",
    "sns.categorical.violinplot(data=a, x='customer_type', y='first_order_revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_both[['customer_type', 'first_order_voucher_revenue_ratio']]\n",
    "sns.categorical.violinplot(data=a, x='customer_type', y='first_order_voucher_revenue_ratio')\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, sharex=True, sharey=True,figsize=(6,6))\n",
    "sns.distplot(a.loc[a.customer_type == 'bad', 'first_order_voucher_revenue_ratio'], ax=ax1, color='red', bins=50)\n",
    "ax1.set_title('Bad Customers')\n",
    "sns.distplot(a.loc[a.customer_type == 'good', 'first_order_voucher_revenue_ratio'], ax=ax2, color='blue', bins=50)\n",
    "ax2.set_title('Good Customers')\n",
    "plt.tight_layout()\n",
    "\n",
    "a.groupby('customer_type').describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_both.loc[df_both.customer_type=='bad'].laundry_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance to Laundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_both.loc[(df_both.laundry_within_1km != -999) & (df_both.experience == 'good'), ['customer_type', 'laundry_distance']]\n",
    "# sns.categorical.violinplot(data=a, x='customer_type', y='laundry_distance')\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, sharex=True, sharey=True,figsize=(6,6))\n",
    "sns.distplot(a.loc[a.customer_type == 'bad', 'laundry_distance'], ax=ax1, color='red', bins=7)\n",
    "ax1.set_title('Bad Customers')\n",
    "sns.distplot(a.loc[a.customer_type == 'good', 'laundry_distance'], ax=ax2, color='blue', bins=7)\n",
    "ax2.set_title('Good Customers')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bad_vs_good_by_column(df_both.loc[df_both.city == \"London\"], 'zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Conclusion*: It doesn't seem that distance to hub plays a role in the first_voucher_order churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_both.loc[df_both.first_order_hub_distance != -999, ['customer_type', 'first_order_hub_distance']]\n",
    "sns.categorical.violinplot(data=a, x='customer_type', y='first_order_hub_distance')\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, sharex=True, sharey=True,figsize=(6,6))\n",
    "sns.distplot(a.loc[a.customer_type == 'bad', 'first_order_hub_distance'], ax=ax1, color='red', bins=25)\n",
    "ax1.set_title('Bad Customers')\n",
    "sns.distplot(a.loc[a.customer_type == 'good', 'first_order_hub_distance'], ax=ax2, color='blue', bins=25)\n",
    "ax2.set_title('Good Customers')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates\n",
    "*Assumption: The dates when more bad customers came than good, could mean that there was a certain period of campaigns that attracted undesirable customers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_limit = df_vou_bad.loc[df_vou_bad.first_order_date < \"2017-07-21\"]\n",
    "good_limit = df_vou_good.loc[df_vou_good.first_order_date < \"2017-07-21\"]\n",
    "bad = bad_limit\\\n",
    "        .groupby('first_order_date')['customer_db_id']\\\n",
    "        .nunique() / bad_limit.shape[0]\n",
    "good = good_limit\\\n",
    "        .groupby('first_order_date')['customer_db_id']\\\n",
    "        .nunique() / good_limit.shape[0]\n",
    "\n",
    "df_plot = pd.concat([bad, good], axis=1, keys=['bad', 'good']).reset_index()\n",
    "df_plot = df_plot.groupby([pd.Grouper(key='first_order_date', freq='MS')])[['bad', 'good']]\\\n",
    "        .sum()\\\n",
    "        .reset_index()\\\n",
    "        .sort_values('first_order_date')\\\n",
    "        .set_index('first_order_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Conclusion*: Seems that there were some areas, especially around Feb - April 2016, where loads of \"bad customers\" were coming in. We should look at what kind of campaigns there were running at that time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facility\n",
    "*Assumption: Some facilities provide better services and therefore customers who churned after first order, although having a 'good' facility, are concidered bad.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bad = df_vou_bad.loc[df_vou_bad.first_order_fac_name != \"unknown\"]\\\n",
    "        .groupby('first_order_fac_name')['customer_db_id'].nunique() / df_vou_bad.shape[0]\n",
    "df_good = df_vou_good.loc[df_vou_good.first_order_fac_name != \"unknown\"]\\\n",
    "        .groupby('first_order_fac_name')['customer_db_id'].nunique() / df_vou_good.shape[0]\n",
    "df_bad_exp = df_vou_bad_exp.loc[df_vou_bad_exp.first_order_fac_name != \"unknown\"]\\\n",
    "        .groupby('first_order_fac_name')['customer_db_id'].nunique() / df_vou_bad_exp.shape[0]\n",
    "df_diff = df_good - df_bad\n",
    "df_diff_relative = df_diff / (df_bad + df_good)\n",
    "df = pd.concat([df_bad, df_good, df_bad_exp, df_diff, df_diff_relative], \n",
    "              axis=1, keys=['bad', 'good', 'bad_exp', 'diff', 'diff_relative'], sort=True)\n",
    "\n",
    "df = df.sort_values('diff', ascending=False)\n",
    "df[['bad', 'good', 'bad_exp']].plot(kind='bar', title='first_order_fac_name')\n",
    "df[['diff']].plot(kind='bar', title='diff (+ more good / - more bad)', color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bad = df_vou_bad.loc[df_vou_bad.first_order_fac_name != \"unknown\"]\\\n",
    "        .groupby('first_order_fac_name')['customer_db_id'].nunique() / df_vou_bad.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Segmentation\n",
    "*Assumption: Bad customers order certain type of products*\n",
    "\n",
    "TODO: too many UNKNOWN values for bad customers, need to include itemization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bad_vs_good_by_column(df_both, 'first_order_products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bad_vs_good_by_column(df_both.loc[df_both.cluster != -999], 'cluster_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates\n",
    "*Assumption: There is a certain pattern in the recency of the second order for the good customers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df_vou_good.first_order_recency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_vou_good.first_order_recency.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance to Laundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_both.loc[(df_both.laundry_distance != -999), ['customer_type', 'laundry_distance']]\n",
    "sns.categorical.violinplot(data=a, x='customer_type', y='laundry_distance')\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, sharex=True, sharey=True,figsize=(6,6))\n",
    "sns.distplot(a.loc[a.customer_type == 'bad', 'laundry_distance'], ax=ax1, color='red', bins=25)\n",
    "ax1.set_title('Bad Customers')\n",
    "sns.distplot(a.loc[a.customer_type == 'good', 'laundry_distance'], ax=ax2, color='blue', bins=25)\n",
    "ax2.set_title('Good Customers')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
