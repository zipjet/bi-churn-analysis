{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Itemization Clustering\n",
    "Cluster customers into groups based on what products they usually order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from scripts import product_processing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/items.csv\") # df with items per order\n",
    "df_orders = pd.read_csv(\"../data/order_churn_data.csv\") # df with orders per customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_orders[[\"customer_db_id\", \"email\", \"order_id\", \"aov\", \"order_state\", \n",
    "                         \"order_created_datetime\", \"frequency\", \"order_num\"]])\n",
    "\n",
    "df = df.loc[df.order_state == \"completed\"] # only get completed orders, to make sure they are itemized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Processing\n",
    "In the DB we have around 400 products -> we have to group them to product groups to reduce dimensionality. This can be done based on text similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Load itemization data from:\n",
    "- https://docs.google.com/spreadsheets/d/1bWyhdLxkGqO6MsCuwc6aaj5ZIPTVXG14AJ_sOKh2-gQ/edit?usp=sharing\n",
    "\n",
    "This sheet was manually created and contains *product_types* and *product_groups*. The unique product names should be grouped to product types based on character similarity, while the product types are groupe to product_groups manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = pd.read_csv(\"../data/products.csv\") # df with IDs and english names for all products\n",
    "products = df_products.product_name.sort_values().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_itemization = pd.read_csv(\"../data/itemization.csv\") \n",
    "df_itemization['product_type_sort'] = df_itemization.product_type_category + '_' + df_itemization.product_type\n",
    "product_types = df_itemization.product_type.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_grouped = product_processing.get_product_types(products, product_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_type</th>\n",
       "      <th>product_group</th>\n",
       "      <th>product_type_category</th>\n",
       "      <th>product_type_sort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#FINILALESSIVE Blouse</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>BUS_Blouse</td>\n",
       "      <td>LAD</td>\n",
       "      <td>LAD_Blouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#LAUNDRYLIBERATION SPECIAL Blouse</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>BUS_Blouse</td>\n",
       "      <td>LAD</td>\n",
       "      <td>LAD_Blouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#WÄSCHEREVOLUTION Blouse</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>BUS_Blouse</td>\n",
       "      <td>LAD</td>\n",
       "      <td>LAD_Blouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12 Blouse Bundle</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>BUS_Blouse</td>\n",
       "      <td>LAD</td>\n",
       "      <td>LAD_Blouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15 Blouse Bundle</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>BUS_Blouse</td>\n",
       "      <td>LAD</td>\n",
       "      <td>LAD_Blouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        product_name product_type product_group  \\\n",
       "0              #FINILALESSIVE Blouse       Blouse    BUS_Blouse   \n",
       "1  #LAUNDRYLIBERATION SPECIAL Blouse       Blouse    BUS_Blouse   \n",
       "2           #WÄSCHEREVOLUTION Blouse       Blouse    BUS_Blouse   \n",
       "3                   12 Blouse Bundle       Blouse    BUS_Blouse   \n",
       "4                   15 Blouse Bundle       Blouse    BUS_Blouse   \n",
       "\n",
       "  product_type_category product_type_sort  \n",
       "0                   LAD        LAD_Blouse  \n",
       "1                   LAD        LAD_Blouse  \n",
       "2                   LAD        LAD_Blouse  \n",
       "3                   LAD        LAD_Blouse  \n",
       "4                   LAD        LAD_Blouse  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products = pd.DataFrame.from_dict(products_grouped, orient='index').reset_index()\n",
    "df_products.columns = ['product_name', 'product_type']\n",
    "df_products = df_products.merge(df_itemization, on='product_type')\n",
    "df_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price_per_unit</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>category</th>\n",
       "      <th>product_name</th>\n",
       "      <th>customer_db_id</th>\n",
       "      <th>email</th>\n",
       "      <th>aov</th>\n",
       "      <th>order_state</th>\n",
       "      <th>order_created_datetime</th>\n",
       "      <th>frequency</th>\n",
       "      <th>order_num</th>\n",
       "      <th>product_type</th>\n",
       "      <th>product_group</th>\n",
       "      <th>product_type_category</th>\n",
       "      <th>product_type_sort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE-PRO-A1270993</td>\n",
       "      <td>DE-X-76260</td>\n",
       "      <td>2016-12-15 02:43:30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DC</td>\n",
       "      <td>misc</td>\n",
       "      <td>Sneaker</td>\n",
       "      <td>57961b83d4cde81c22ffbe2b</td>\n",
       "      <td>anyafriesen@gmail.com</td>\n",
       "      <td>55.882353</td>\n",
       "      <td>completed</td>\n",
       "      <td>2016-07-25 16:00:36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Boots / Shoes / Sneaker</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>ACC</td>\n",
       "      <td>ACC_Boots / Shoes / Sneaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE-PRO-B1255636</td>\n",
       "      <td>DE-X-76260</td>\n",
       "      <td>2016-12-15 02:43:30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>WF</td>\n",
       "      <td>washnfold</td>\n",
       "      <td>Wash and Fold (per kg)</td>\n",
       "      <td>57961b83d4cde81c22ffbe2b</td>\n",
       "      <td>anyafriesen@gmail.com</td>\n",
       "      <td>55.882353</td>\n",
       "      <td>completed</td>\n",
       "      <td>2016-07-25 16:00:36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wash and Fold / Bag of Folded Laundry / Colour Separation</td>\n",
       "      <td>WashFold</td>\n",
       "      <td>MIX</td>\n",
       "      <td>MIX_Wash and Fold / Bag of Folded Laundry / Colour Separation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE-PRO-D1330444</td>\n",
       "      <td>DE-X-76260</td>\n",
       "      <td>2016-12-15 02:43:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>HH</td>\n",
       "      <td>drycleaning</td>\n",
       "      <td>Pillow case</td>\n",
       "      <td>57961b83d4cde81c22ffbe2b</td>\n",
       "      <td>anyafriesen@gmail.com</td>\n",
       "      <td>55.882353</td>\n",
       "      <td>completed</td>\n",
       "      <td>2016-07-25 16:00:36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Pillow case</td>\n",
       "      <td>HH_pillow_case</td>\n",
       "      <td>HH</td>\n",
       "      <td>HH_Pillow case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE-PRO-G4166715</td>\n",
       "      <td>DE-X-76260</td>\n",
       "      <td>2016-12-15 02:43:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>HH</td>\n",
       "      <td>drycleaning</td>\n",
       "      <td>Duvet cover</td>\n",
       "      <td>57961b83d4cde81c22ffbe2b</td>\n",
       "      <td>anyafriesen@gmail.com</td>\n",
       "      <td>55.882353</td>\n",
       "      <td>completed</td>\n",
       "      <td>2016-07-25 16:00:36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Duvet</td>\n",
       "      <td>HH_blanket</td>\n",
       "      <td>HH</td>\n",
       "      <td>HH_Duvet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE-PRO-Y9074269</td>\n",
       "      <td>DE-X-76260</td>\n",
       "      <td>2016-12-15 02:43:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>HH</td>\n",
       "      <td>drycleaning</td>\n",
       "      <td>Bed sheet</td>\n",
       "      <td>57961b83d4cde81c22ffbe2b</td>\n",
       "      <td>anyafriesen@gmail.com</td>\n",
       "      <td>55.882353</td>\n",
       "      <td>completed</td>\n",
       "      <td>2016-07-25 16:00:36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bedsheets</td>\n",
       "      <td>HH_linens</td>\n",
       "      <td>HH</td>\n",
       "      <td>HH_Bedsheets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        product_id    order_id           order_date  quantity  price_per_unit  \\\n",
       "0  DE-PRO-A1270993  DE-X-76260  2016-12-15 02:43:30       3.0            15.0   \n",
       "1  DE-PRO-B1255636  DE-X-76260  2016-12-15 02:43:30       4.0             4.5   \n",
       "2  DE-PRO-D1330444  DE-X-76260  2016-12-15 02:43:30       1.0             3.5   \n",
       "3  DE-PRO-G4166715  DE-X-76260  2016-12-15 02:43:30       1.0             5.0   \n",
       "4  DE-PRO-Y9074269  DE-X-76260  2016-12-15 02:43:30       1.0             5.0   \n",
       "\n",
       "  segmentation     category            product_name            customer_db_id  \\\n",
       "0           DC         misc                 Sneaker  57961b83d4cde81c22ffbe2b   \n",
       "1           WF    washnfold  Wash and Fold (per kg)  57961b83d4cde81c22ffbe2b   \n",
       "2           HH  drycleaning             Pillow case  57961b83d4cde81c22ffbe2b   \n",
       "3           HH  drycleaning             Duvet cover  57961b83d4cde81c22ffbe2b   \n",
       "4           HH  drycleaning               Bed sheet  57961b83d4cde81c22ffbe2b   \n",
       "\n",
       "                   email        aov order_state order_created_datetime  \\\n",
       "0  anyafriesen@gmail.com  55.882353   completed    2016-07-25 16:00:36   \n",
       "1  anyafriesen@gmail.com  55.882353   completed    2016-07-25 16:00:36   \n",
       "2  anyafriesen@gmail.com  55.882353   completed    2016-07-25 16:00:36   \n",
       "3  anyafriesen@gmail.com  55.882353   completed    2016-07-25 16:00:36   \n",
       "4  anyafriesen@gmail.com  55.882353   completed    2016-07-25 16:00:36   \n",
       "\n",
       "   frequency  order_num  \\\n",
       "0        0.0          1   \n",
       "1        0.0          1   \n",
       "2        0.0          1   \n",
       "3        0.0          1   \n",
       "4        0.0          1   \n",
       "\n",
       "                                                product_type   product_group  \\\n",
       "0                                    Boots / Shoes / Sneaker     Accessories   \n",
       "1  Wash and Fold / Bag of Folded Laundry / Colour Separation        WashFold   \n",
       "2                                                Pillow case  HH_pillow_case   \n",
       "3                                                      Duvet      HH_blanket   \n",
       "4                                                  Bedsheets       HH_linens   \n",
       "\n",
       "  product_type_category  \\\n",
       "0                   ACC   \n",
       "1                   MIX   \n",
       "2                    HH   \n",
       "3                    HH   \n",
       "4                    HH   \n",
       "\n",
       "                                               product_type_sort  \n",
       "0                                    ACC_Boots / Shoes / Sneaker  \n",
       "1  MIX_Wash and Fold / Bag of Folded Laundry / Colour Separation  \n",
       "2                                                 HH_Pillow case  \n",
       "3                                                       HH_Duvet  \n",
       "4                                                   HH_Bedsheets  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(df_products, how='left', on='product_name')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Customer based on Product Groups\n",
    "Each product_type belongs to a product_group. We want to find clusters of customers who order the same product_groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each customer and product_group get how many orders this group was included in and in what quantity\n",
    "df_cust = df.groupby(['customer_db_id', 'product_group'])\\\n",
    "            .agg({'quantity': 'sum', 'order_id': 'nunique', 'frequency': 'min'})\\\n",
    "            .reset_index()\\\n",
    "            .set_index('customer_db_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummy values of customers and product_groups\n",
    "df_dumm = pd.get_dummies(df_cust['product_group'])\n",
    "# group all dummies for one customer into one row\n",
    "df_dumm = df_dumm.reset_index().groupby(['customer_db_id']).max()\n",
    "df_dumm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train K-Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_dumm.values\n",
    "# m_km = KMeans(n_clusters=10)\n",
    "# m_km.fit(X)\n",
    "# m_clusters = m_km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(m_km, 'data/models/best_items_clf.pkl') \n",
    "m_km = joblib.load('data/models/best_items_clf.pkl') \n",
    "m_clusters = m_km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustered = df_dumm.copy()\n",
    "df_clustered['cluster'] = m_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_names = {0: 'Shirt+Trousers', \n",
    "                 1: 'Shirt+Trousers+Suit+Blazer',\n",
    "                 2: 'Shirt',\n",
    "                 3: 'WashFold',\n",
    "                 4: 'Suit+Shirt',\n",
    "                 5: 'Jackets+Coats',\n",
    "                 6: 'Suit',\n",
    "                 7: 'Dress+Blouse+Skirt+Top',\n",
    "                 8: 'Mix',\n",
    "                 9: 'Household'}\n",
    "df_clustered['cluster_name'] = df_clustered.cluster.map(cluster_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clustered.groupby(['cluster_name'])['Accessories'].count().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get average frequency per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustered = df_clustered.join(df.groupby('customer_db_id')['frequency'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_freq = df_clustered.loc[df_clustered.frequency > 0]\\\n",
    "                .groupby('cluster_name')\\\n",
    "                .agg({'frequency': ['mean', 'median']})\\\n",
    "                .reset_index()\n",
    "df_avg_freq.columns = df_avg_freq.columns.droplevel()\n",
    "df_avg_freq.columns = ['cluster_name', 'freq_mean', 'freq_median']\n",
    "df_avg_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustered = df_clustered.reset_index().merge(df_avg_freq, on='cluster_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustered.to_csv('data/clustered_customers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot cluster centers and avg frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = pd.DataFrame(data=m_km.cluster_centers_, columns=df_dumm.columns)\n",
    "centers.index = centers.index.map(cluster_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "centers.head()\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.heatmap(centers.sort_index().T, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "sns.set()\n",
    "sns.categorical.boxplot(data=df_clustered.loc[(df_clustered.frequency < 365) & (df_clustered.frequency > 0)], \n",
    "                           x='cluster_name', y='frequency',\n",
    "                           order=sorted(df_clustered.cluster_name.unique().tolist()))\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nps = pd.read_csv(\"data/NPS.csv\")\n",
    "df_nps = df_nps[['email', 'How often do you use a dry cleaner and/or launderette?', 'file']]\n",
    "df_nps.columns = ['email', 'NPS_frequency', 'file']\n",
    "\n",
    "translations = {'Toutes les deux semaines': 'Bi-Weekly',\n",
    "               'Chaque mois': 'Monthly',\n",
    "               'Moins que chaque trimestre': 'Less than quarterly',\n",
    "               'Chaque trimestre': 'Quarterly',\n",
    "               'Chaque semaine': 'Weekly',\n",
    "               'Weniger oft': 'Less than quarterly',\n",
    "               'VierteljÃ¤hrlich': 'Quarterly',\n",
    "               'ZweiwÃ¶chentlich': 'Bi-Weekly',\n",
    "               'Monatlich': 'Monthly',\n",
    "               'WÃ¶chentlich': 'Weekly'}\n",
    "\n",
    "sorting = {'Weekly': '0_Weekly',\n",
    "          'Bi-Weekly': '1_Bi-Weekly',\n",
    "          'Monthly': '2_Monthly',\n",
    "          'Quarterly': '3_Quarterly',\n",
    "          'Less than quarterly': '4_Less than quarterly'}\n",
    "\n",
    "df_nps.loc[df_nps.file.isin(['DE.csv', 'FR.csv']), 'NPS_frequency'] = df_nps.NPS_frequency.map(translations)\n",
    "df_nps.NPS_frequency = df_nps.NPS_frequency.map(sorting)\n",
    "df_nps = df_nps[['email', 'NPS_frequency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nps_cluster = df_clustered.groupby(['cluster', 'NPS_frequency'])['customer_db_id'].nunique().reset_index()\n",
    "df_nps_cluster_total = df_clustered.loc[~df_clustered.NPS_frequency.isnull()]\\\n",
    "                                    .groupby(['cluster'])['customer_db_id'].nunique()\\\n",
    "                                    .reset_index().rename(columns={'customer_db_id': 'cluster_total'})\n",
    "df_nps_cluster = df_nps_cluster.merge(df_nps_cluster_total, how='left', on='cluster')\n",
    "df_nps_cluster['cluster_freq'] = df_nps_cluster.customer_db_id / df_nps_cluster.cluster_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nps_cluster_pivot = df_nps_cluster.pivot(index='NPS_frequency', columns='cluster', values='cluster_freq')\n",
    "sns.heatmap(df_nps_cluster_pivot, cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clustered.to_csv('data/clustered_customers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_clustered.reset_index()[['customer_db_id', 'cluster']], on='customer_db_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('cluster')['aov'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nps_products = df.loc[~df.NPS_frequency.isnull()]\\\n",
    "                    .groupby(['NPS_frequency', 'product_group'])['customer_db_id']\\\n",
    "                    .nunique().reset_index()\n",
    "df_nps_products_total = df.loc[~df.NPS_frequency.isnull()]\\\n",
    "                    .groupby(['product_group'])['customer_db_id']\\\n",
    "                    .nunique().reset_index()\\\n",
    "                    .rename(columns={'customer_db_id': 'product_group_total'})\n",
    "df_nps_products = df_nps_products.merge(df_nps_products_total, on='product_group', how='left')\n",
    "df_nps_products['customers_ratio'] = df_nps_products.customer_db_id / df_nps_products.product_group_total\n",
    "df_nps_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nps_products_pivot = df_nps_products.pivot(index='product_group', columns='NPS_frequency', values='customer_db_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.heatmap(df_nps_products_pivot, cmap='Greens', yticklabels=df_nps_products_pivot.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
